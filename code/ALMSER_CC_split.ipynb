{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split into train and test pairs based on connected components.\n",
    "Ensures that there are no records referring to the same real world entity in train and test sets.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matching Pairs:  4827\n",
      "Non-Matching Pairs:  69680\n",
      "Counter({2: 1005, 3: 309, 4: 224, 5: 131, 6: 74, 7: 53})\n",
      "1796\n",
      "Components train:  1257\n",
      "Components test:  539\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import networkx as nx\n",
    "from collections import Counter\n",
    "import random\n",
    "\n",
    "pairs_fv= pd.read_csv(output_path+\"pairs_fv.csv\")\n",
    "\n",
    "matching_pairs = pairs_fv[pairs_fv.label]\n",
    "non_matching_pairs = pairs_fv[~pairs_fv.label]\n",
    "\n",
    "print(\"Matching Pairs: \", matching_pairs.shape[0])\n",
    "print(\"Non-Matching Pairs: \", non_matching_pairs.shape[0])\n",
    "\n",
    "\n",
    "Graphtype = nx.Graph()\n",
    "G = nx.from_pandas_edgelist(matching_pairs, source= 'source', target='target', create_using=Graphtype)\n",
    "\n",
    "con_components = list(nx.connected_components(G))\n",
    "subgraphs =  [G.subgraph(c).copy() for c in nx.connected_components(G)]\n",
    "con_components_lengths = [len(x) for x in con_components]\n",
    "print(Counter(con_components_lengths))\n",
    "print(len(subgraphs))\n",
    "\n",
    "random.Random(42).shuffle(con_components)\n",
    "train_components = con_components[:int(0.7*len(con_components))]\n",
    "\n",
    "\n",
    "test_components = con_components[int(0.7*len(con_components)):]\n",
    "\n",
    "print(\"Components train: \", len(train_components))\n",
    "print(\"Components test: \", len(test_components))\n",
    "\n",
    "subgraph_train = [G.subgraph(c).copy() for c in train_components]\n",
    "train_graph = nx.compose_all(subgraph_train)\n",
    "subgraph_test = [G.subgraph(c).copy() for c in test_components]\n",
    "test_graph = nx.compose_all(subgraph_test)\n",
    "\n",
    "pairs_fv['train_or_test'] = 'not_assigned'\n",
    "clean_train_neg=0\n",
    "clean_test_neg=0\n",
    "for ind, row in pairs_fv.iterrows():\n",
    "    is_match = row['label']\n",
    "    assigned=False\n",
    "    if is_match and train_graph.has_edge(row.source,row.target):\n",
    "        pairs_fv.at[ind, 'train_or_test']='train'\n",
    "        assigned=True\n",
    "    if is_match and test_graph.has_edge(row.source,row.target):\n",
    "        if assigned: \n",
    "            import pdb;pdb.set_trace();\n",
    "            print(\"Already assigned\")\n",
    "        pairs_fv.at[ind, 'train_or_test']='test'\n",
    "        assigned=True\n",
    "    if not(is_match) and train_graph.has_node(row.source) and train_graph.has_node(row.target):\n",
    "        clean_train_neg +=1 \n",
    "        pairs_fv.at[ind, 'train_or_test']='train'\n",
    "        if assigned:\n",
    "            import pdb;pdb.set_trace();\n",
    "            print(\"Already assigned\")\n",
    "        assigned=True\n",
    "    if not(is_match) and test_graph.has_node(row.source) and test_graph.has_node(row.target):\n",
    "        clean_test_neg +=1 \n",
    "        pairs_fv.at[ind, 'train_or_test']='test'\n",
    "        if assigned: \n",
    "            import pdb;pdb.set_trace();\n",
    "            print(\"Already assigned\")\n",
    "        assigned=True\n",
    "    elif not(is_match):\n",
    "        flip = random.randint(1, 10)\n",
    "        if flip<=3: pairs_fv.at[ind, 'train_or_test']='test'\n",
    "        else:  pairs_fv.at[ind, 'train_or_test']='train'\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "positives distribution\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Counter({'train': 3424, 'test': 1403})"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "negatives destribution\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Counter({'train': 47307, 'test': 22373})"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clean train negatives: 11451\n",
      "clean test negatives: 1963\n"
     ]
    }
   ],
   "source": [
    "#save\n",
    "print(\"positives distribution\")\n",
    "display(Counter(pairs_fv[pairs_fv.label]['train_or_test']))\n",
    "print(\"negatives destribution\")\n",
    "display(Counter(pairs_fv[~pairs_fv.label]['train_or_test']))\n",
    "print(\"clean train negatives:\", clean_train_neg)\n",
    "print(\"clean test negatives:\", clean_test_neg)\n",
    "\n",
    "train_fv= pairs_fv[pairs_fv.train_or_test=='train'].drop(columns=['train_or_test'])\n",
    "test_fv= pairs_fv[pairs_fv.train_or_test=='test'].drop(columns=['train_or_test'])\n",
    "\n",
    "train_fv.to_csv(output_path+\"train_pairs_fv.csv\", index= False)\n",
    "test_fv.to_csv(output_path+\"test_pairs_fv.csv\", index= False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
